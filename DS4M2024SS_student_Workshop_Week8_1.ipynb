{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gr22dTVSccurYG9z4nX2p-JaOaVEL567","timestamp":1710437989439}],"toc_visible":true,"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOsqEY+PLyFuMVDnwZ3WJXd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Data Science for Manufacturing - Workshop 8-1: Introduction to Deep Learning\n","\n","\n"],"metadata":{"id":"i60RkXtA3o_2"}},{"cell_type":"markdown","source":["## Objectives\n","- Review of Tensorflow and Keras\n","- Keras for a simple Convolutional Neural Network (CNN)\n"," - Load in the dataset, show example individuals\n"," - Prepare the dataset for DL models\n","    - One-hot encoding\n","    - Normalisation\n","- Build the model: three building blocks\n","  - Model definition: instanciate deep learning layers\n","  - Model compiling: define the loss function, metric, optimiser\n","  - Model training: use train data to train the model\n","- Hyperparameter tuning\n","  - Batch size\n","  - Learning rate\n","\n","## Other\n","- Highly recommended resource: [Book: Dive into Deep Learning](https://d2l.ai/)\n","- There is no expectation of applying DL models in assignment 2"],"metadata":{"id":"9ouPXH20B0K7"}},{"cell_type":"markdown","source":["## 1. Review of Tensorflow and Keras"],"metadata":{"id":"FqQ0fOmOGb_J"}},{"cell_type":"code","source":[],"metadata":{"id":"CnlcbuB2BfE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"egFfaDr3Be6m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Introduction to the dataset\n"],"metadata":{"id":"4i9TBTcyGJ_U"}},{"cell_type":"code","source":[],"metadata":{"id":"h3Nb1mOhBiMm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iyktwIn1Bh6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OIXmLsYyBhrQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(60000, 28, 28) here means:\n","- There are 60000 image individuals in the train dataset\n","- Each image has a size of 28*28"],"metadata":{"id":"x0egwqcuzNaN"}},{"cell_type":"code","source":[],"metadata":{"id":"9DTTTTzNBk1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DNg6gqO9BkaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qC_JJFFoBkJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vzf79rBRBj_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CK3CwY76BoaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aA-118P5Bn08"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Problem to solve:\n","- Train a CNN to recognise and classify the hand-written digits."],"metadata":{"id":"12bU1n31ekOy"}},{"cell_type":"markdown","source":["## 3. Prepare the data for DL models\n","Feature data:\n","- The image data, x, should be float type, instead of unit8 type.\n","- Pixel values should be normalised. Pixel values usually range from 0 to 255, by /255, the range of pixel values is scaled to [0, 1].\n","- Convolutional layers for images in Keras only receive images with RGB channels, which contains 3 channels, in the format of (pixel number, pixel number, channel). An example is (224, 224, 3). Therefore the dimension of each picture (28, 28) here needs to be expandded by 1 extra dimension.\n","\n"],"metadata":{"id":"wBC-bO3aJWij"}},{"cell_type":"markdown","source":["Label data:\n","- The label data, y, should be categorical data described by numeric types, instead of unit8.\n","\n","![One-hot encoding](https://media.licdn.com/dms/image/D4E12AQHFBow7MerIqw/article-inline_image-shrink_1000_1488/0/1704601209165?e=1714608000&v=beta&t=gQPFX7NihUfEQYW4CN6XIvUCW7gt-egdU_PUFT_tPz0)"],"metadata":{"id":"oERDGnLGF0pY"}},{"cell_type":"code","source":[],"metadata":{"id":"JJDxilYXByk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yUVcbdyDBybC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c_LnV2X9Bz07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HhOy2fT1BxfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kJXbTExtBxUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XMcK707DBxJg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(60000, 10) here means:\n","- As in the image feature dataset, there are 60000 individuals\n","- A single unit8 is converted to 10-digit one-hot coding vectors"],"metadata":{"id":"kO3UemBX0BBW"}},{"cell_type":"code","source":[],"metadata":{"id":"64XoAJ3dB5Dt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Build the model\n","Types of DL models:\n","- CNNs:\n","  - tasks: computer vision related tasks, such as image classification, object detection, image segmentation, and facial recognition\n","  - data: structure spatial data, images\n","  - successful models: ResNet, VGGNet, InceptionNet\n","- RNNs (recurrent neural network):\n","  - tasks: natural language processing (NLP), time series prediction, speech recognition, language translation\n","  - data: sequential/time series data, text data, financial data, etc\n","  - successful models: LTSM, GRU\n","- Transformers:\n","  - tasks: natural language understanding, language generation, machine translation\n","  - data: tokenised text sequences\n","  - successful models: GPT, BERT\n","\n","<br>\n","\n","Building up and training a model in Keras and Tensorflow:\n","- model definition\n","- model compiling\n","- model training"],"metadata":{"id":"dzOoOSvg0_cD"}},{"cell_type":"markdown","source":["### 4.1 Model definition\n","Baisc elements of a CNN:\n","- convolutional layers\n","- pooling layers\n","- dense layers (mlp)\n","\n","Optional elements of a CNN:\n","- dropout layers\n","- batch normalisation layers"],"metadata":{"id":"8pkTkyNaiGXo"}},{"cell_type":"code","source":[],"metadata":{"id":"jH-gBy9mCChN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P4F96D6jCCX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bp4gh9CUCCN3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2 Model compiling\n","Basic elements of model compilings:\n","- loss function: used to update weights\n","  - categorical loss for classification tasks\n","  - MSE (mean squared error), MAE (mean absolute error) for regression tasks\n","- evaluation metric: not used to update weights, but providing additional insights into the model's behaviour. More human-understandable than loss\n","  - accuracy, the most commonly used metric for classification task\n","- optimiser: optimisation algorithm used to update weights\n","  - 'adam', 'RMSprop', the most commonly used optimisers for common DL models"],"metadata":{"id":"DbW8VkMXtALI"}},{"cell_type":"code","source":[],"metadata":{"id":"X7qTVB9CCEwF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.3 Model training\n","Basic elements of model training:\n","- batch size: the size of sample data a model is looking at during an iteration\n","  - common batch size ranges:\n","    - small batch size (2-32)\n","    - medium batch size (32-128)\n","    - large batch size (128-512+)\n","    - full batch (batch size equal to dataset size)\n","  - selecting a batch size:\n","    - in general, a batch size of 32, 64, 128 should work well\n","    - large batch size may lead to smoother convergence, but is highly demanding on computational resources\n","    - small batch size may lead to quicker training processes, but can introduce noise, and sometimes the noise can be too big for the model to converge\n","\n","- number epochs: number of iterations of optimisation process\n","  - depend on the size and complexity of the datasets and the model\n","\n","- datasets for training: data the model used to update weights\n","  \n","- datasets for validation: data the model used to reflect the performances during training, not used for weight updates\n","  - common training/validation ratio: 9/1, 8/2"],"metadata":{"id":"X9VAoJDmxdHk"}},{"cell_type":"code","source":[],"metadata":{"id":"SzNAnJpGCF0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RJMTVeY8CG75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Evaluation and predictions with the trained model"],"metadata":{"id":"R149eWKe8XOz"}},{"cell_type":"code","source":[],"metadata":{"id":"VPrlq05tCkEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GsNCw082CWzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"14yxwErmCmD8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hSM7ajm7Cl5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q7FIx4fDCpZs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Hyperparameter tuning\n","Common hyperparameters:\n","- Batch size\n","- Learning rate\n","- Number of epochs\n","- Optimiser\n","- Number of layers and neuron units on each layer\n","- ..."],"metadata":{"id":"NWAvzfJ1DwpS"}},{"cell_type":"markdown","source":["Because plotting learning curves is needed in every experiment, so it's good to create a function for it."],"metadata":{"id":"UcDGriU5GX47"}},{"cell_type":"code","source":[],"metadata":{"id":"S0vBoo4sCqZH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6.1 Batch size"],"metadata":{"id":"sWqTpt6BEBNO"}},{"cell_type":"markdown","source":["£££ When ever modifying your model, either it's a hyperparameter or other configurations, to make your modifications effective, rerun the three building blocks of a deep learning model."],"metadata":{"id":"PO5o2epwRq0N"}},{"cell_type":"code","source":[],"metadata":{"id":"80pokqKSCrt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sQnt_lEJCtWx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The effects of batch size:\n","- Batch sizes too small make convergence fluctuating more. In worst scenarios, there will not be a proper convergence at all.\n","- Batch sizes too big make training really slow, sometimes it can be too big for a program to run."],"metadata":{"id":"Lh1NG7mZFzsm"}},{"cell_type":"markdown","source":["### 6.2 Learning rate"],"metadata":{"id":"TpkB-ocAGQ_P"}},{"cell_type":"code","source":[],"metadata":{"id":"gQam_bdeC2N8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r-cJLqTVC2Dw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The effects of learning rates:\n","- Learning rates too small make the learning process really slow, and within a numer of epochs, the model may not learn enough.\n","- Learning rates too big make the learning process run fast in the beginning, but when approaching convergence, it may not converge to the optimal level because of the rough accuracy level of a step, i.e. learning rate."],"metadata":{"id":"23Nr5q79HZSP"}},{"cell_type":"markdown","source":["### 6.3 More hyperparameters"],"metadata":{"id":"0V9-M7LNd7Zf"}},{"cell_type":"code","source":["\"\"\"\n","Homework: modify other hyperparameters and see how they affect the performances\n","\"\"\""],"metadata":{"id":"VeIACZPLHU-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eXwBWDBIeKpD"},"execution_count":null,"outputs":[]}]}